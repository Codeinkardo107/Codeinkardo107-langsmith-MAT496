{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set them inline\n",
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_API_KEY\"] = \"\"\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langsmith-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Or you can use a .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(dotenv_path=\"../../.env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the RAG Application that we've been working with throughout this course"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "from langchain_community.vectorstores import SKLearnVectorStore\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langsmith import traceable\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "import nest_asyncio\n",
    "\n",
    "# TODO: Configure this model!\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "APP_VERSION = 1.0\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the latest question in the conversation. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def get_vector_db_retriever():\n",
    "    persist_path = os.path.join(tempfile.gettempdir(), \"union.parquet\")\n",
    "    embd = OpenAIEmbeddings()\n",
    "\n",
    "    # If vector store exists, then load it\n",
    "    if os.path.exists(persist_path):\n",
    "        vectorstore = SKLearnVectorStore(\n",
    "            embedding=embd,\n",
    "            persist_path=persist_path,\n",
    "            serializer=\"parquet\"\n",
    "        )\n",
    "        return vectorstore.as_retriever(lambda_mult=0)\n",
    "\n",
    "    # Otherwise, index LangSmith documents and create new vector store\n",
    "    ls_docs_sitemap_loader = SitemapLoader(web_path=\"https://docs.smith.langchain.com/sitemap.xml\", continue_on_failure=True)\n",
    "    ls_docs = ls_docs_sitemap_loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "        chunk_size=500, chunk_overlap=0\n",
    "    )\n",
    "    doc_splits = text_splitter.split_documents(ls_docs)\n",
    "\n",
    "    vectorstore = SKLearnVectorStore.from_documents(\n",
    "        documents=doc_splits,\n",
    "        embedding=embd,\n",
    "        persist_path=persist_path,\n",
    "        serializer=\"parquet\"\n",
    "    )\n",
    "    vectorstore.persist()\n",
    "    return vectorstore.as_retriever(lambda_mult=0)\n",
    "\n",
    "nest_asyncio.apply()\n",
    "retriever = get_vector_db_retriever()\n",
    "\n",
    "\"\"\"\n",
    "retrieve_documents\n",
    "- Returns documents fetched from a vectorstore based on the user's question\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    return retriever.invoke(question)\n",
    "\n",
    "\"\"\"\n",
    "generate_response\n",
    "- Calls `call_openai` to generate a model response after formatting inputs\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": RAG_SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Context: {formatted_docs} \\n\\n Question: {question}\"\n",
    "        }\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "\"\"\"\n",
    "call_openai\n",
    "- Returns the chat completion output from OpenAI\n",
    "\"\"\"\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\n",
    "        \"ls_provider\": MODEL_PROVIDER,\n",
    "        \"ls_model_name\": MODEL_NAME\n",
    "    }\n",
    ")\n",
    "def call_openai(messages: List[dict]) -> str:\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "\"\"\"\n",
    "langsmith_rag\n",
    "- Calls `retrieve_documents` to fetch documents\n",
    "- Calls `generate_response` to generate a response based on the fetched documents\n",
    "- Returns the model response\n",
    "\"\"\"\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a code snippet that should look similar to what you see from the starter code!\n",
    "\n",
    "There are a few important components here.\n",
    "\n",
    "1. We have defined an Evaluator\n",
    "2. We pipe our dataset examples (dict) to the shape of input that our function `langsmith_rag` takes (str) using a target function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-4o-3a076123' at:\n",
      "https://smith.langchain.com/o/6b354ec6-3f46-4558-9cde-6a933975f725/datasets/1f9560b2-c8e9-4460-8d1e-9a99f230e018/compare?selectedSessions=c36abf0d-04b5-45d5-bd76-f1a0ea5068e8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "10it [01:02,  6.28s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation. It ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>41.444713</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>b8258152-82bb-4296-9254-df4151a676e1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>2.074160</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>ade1856d-dd82-4d51-9428-a6838c818a2f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>To pass metadata with the `@traceable` decorat...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.453570</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>3eba5668-cb4c-4252-9057-ba16a2995a08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith with LangChain,...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.369347</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>3e27b1cb-0390-4581-8894-dc1aa30d15e9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback using the LangSmith SD...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.879833</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>d8fef360-fcf9-4ca3-a31d-fd58d6fe16f7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is primarily a platform for obse...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.887516</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>0dcb6c65-fddb-4f74-aa11-79003b62b5d7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is used for building production-grad...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.572325</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>748bbaf5-02a4-48c4-86b3-2f9a9e99f327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.096829</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>1c583067-9f44-4a17-9b6e-0159d9fe64dd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith allows users to run multiple experim...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.884860</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>dfb00758-9b5f-4e21-a13b-4c71af34ef90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>No, LangSmith focuses on online evaluations, p...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.575760</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>05bfbd1b-86ff-40f8-a307-ac4c20693e9c</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-4o-3a076123>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "\n",
    "client = Client()\n",
    "dataset_name = \"Dataset_1\"\n",
    "\n",
    "def is_concise_enough(reference_outputs: dict, outputs: dict) -> dict:\n",
    "    score = len(outputs[\"output\"]) < 1.5 * len(reference_outputs[\"output\"])\n",
    "    return {\"key\": \"is_concise\", \"score\": int(score)}\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-4o\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying your Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's change our model to gpt-35-turbo and see how it performs!\n",
    "\n",
    "Make this change, and then run this code snippet!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'gpt-3.5-turbo-7440f1c4' at:\n",
      "https://smith.langchain.com/o/6b354ec6-3f46-4558-9cde-6a933975f725/datasets/1f9560b2-c8e9-4460-8d1e-9a99f230e018/compare?selectedSessions=c99b41b5-271c-4e84-b081-99484969163c\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:04,  2.24s/it]Error running target function: Error code: 400 - {'error': {'message': 'something went wrong reading your request', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1924, in _forward\n",
      "    fn(*args, langsmith_extra=langsmith_extra)\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 703, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bhavy\\AppData\\Local\\Temp\\ipykernel_23256\\862480817.py\", line 5, in target_function\n",
      "    return langsmith_rag(inputs[\"question\"])\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 703, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bhavy\\AppData\\Local\\Temp\\ipykernel_23256\\252468420.py\", line 110, in langsmith_rag\n",
      "    documents = retrieve_documents(question)\n",
      "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 703, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bhavy\\AppData\\Local\\Temp\\ipykernel_23256\\252468420.py\", line 64, in retrieve_documents\n",
      "    return retriever.invoke(question)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_core\\retrievers.py\", line 263, in invoke\n",
      "    result = self._get_relevant_documents(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_core\\vectorstores\\base.py\", line 1067, in _get_relevant_documents\n",
      "    docs = self.vectorstore.similarity_search(query, **kwargs_)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\sklearn.py\", line 256, in similarity_search\n",
      "    docs_scores = self.similarity_search_with_score(query, k=k, **kwargs)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_community\\vectorstores\\sklearn.py\", line 238, in similarity_search_with_score\n",
      "    query_embedding = self._embedding_function.embed_query(query)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 640, in embed_query\n",
      "    return self.embed_documents([text], **kwargs)[0]\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 592, in embed_documents\n",
      "    return self._get_len_safe_embeddings(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langchain_openai\\embeddings\\base.py\", line 482, in _get_len_safe_embeddings\n",
      "    response = self.client.create(\n",
      "               ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\openai\\resources\\embeddings.py\", line 132, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1259, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\openai\\_base_client.py\", line 1047, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': 'something went wrong reading your request', 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
      "Error running evaluator <DynamicRunEvaluator is_concise_enough> on run 6e1c1c7a-7faa-4979-9c36-2f9699c3427a: TypeError(\"object of type 'NoneType' has no len()\")\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py\", line 1620, in _run_evaluators\n",
      "    evaluator_response = evaluator.evaluate_run(  # type: ignore[call-arg]\n",
      "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 351, in evaluate_run\n",
      "    result = self.func(\n",
      "             ^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\run_helpers.py\", line 703, in wrapper\n",
      "    function_result = run_container[\"context\"].run(\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\evaluator.py\", line 777, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\bhavy\\AppData\\Local\\Temp\\ipykernel_23256\\1910702357.py\", line 7, in is_concise_enough\n",
      "    score = len(outputs[\"output\"]) < 1.5 * len(reference_outputs[\"output\"])\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: object of type 'NoneType' has no len()\n",
      "10it [04:14, 25.41s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "      <th>feedback.wrapper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation. It ...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.492683</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>b3c600d4-658d-4adb-8153-48e8e062e73e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.052750</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>9d6b9732-ca50-4b51-a1e3-e29782dead72</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>None</td>\n",
       "      <td>BadRequestError(\"Error code: 400 - {'error': {...</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>115.299205</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>6e1c1c7a-7faa-4979-9c36-2f9699c3427a</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith using LangChain...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.145344</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>96d73696-1797-4aa1-9835-1a9f56e44c44</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.041513</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>77ed38ce-5649-449e-98d2-56ffa7305c66</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>LangSmith is designed for LLM observability an...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.138430</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>288cd61f-9067-43fe-adeb-d45389040a2e</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is a platform for building productio...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.871908</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>1194123b-413d-4709-a42e-038518298f0b</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>119.187324</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>e4c38734-05d0-4f4b-8a26-23e0b7f96297</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith allows you to run multiple experimen...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.874613</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>7c523988-72df-4db6-9b1c-6d35cfbd2c65</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>No, LangSmith primarily supports online evalua...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.494201</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>309ca5e2-49d3-462e-8460-c1528fa28a25</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults gpt-3.5-turbo-7440f1c4>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langsmith import evaluate, Client\n",
    "from langsmith.schemas import Example, Run\n",
    "\n",
    "def target_function(inputs: dict):\n",
    "    return langsmith_rag(inputs[\"question\"])\n",
    "\n",
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"gpt-3.5-turbo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langsmith import traceable, evaluate, Client\n",
    "from openai import OpenAI\n",
    "from typing import List\n",
    "\n",
    "# Configuration\n",
    "MODEL_NAME = \"gpt-4o\"\n",
    "MODEL_PROVIDER = \"openai\"\n",
    "RAG_SYSTEM_PROMPT = \"\"\"You are an assistant for question-answering tasks. \n",
    "Use the following pieces of retrieved context to answer the question. \n",
    "If you don't know the answer, just say that you don't know. \n",
    "Use three sentences maximum and keep the answer concise.\n",
    "\"\"\"\n",
    "\n",
    "client = Client()\n",
    "openai_client = OpenAI()\n",
    "\n",
    "# Core RAG functions\n",
    "@traceable(run_type=\"chain\")\n",
    "def retrieve_documents(question: str):\n",
    "    # Your retrieval logic here\n",
    "    return []  # Mock documents\n",
    "\n",
    "@traceable(\n",
    "    run_type=\"llm\",\n",
    "    metadata={\"ls_provider\": MODEL_PROVIDER, \"ls_model_name\": MODEL_NAME}\n",
    ")\n",
    "def call_openai(messages: List[dict]):\n",
    "    return openai_client.chat.completions.create(\n",
    "        model=MODEL_NAME,\n",
    "        messages=messages,\n",
    "    )\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def generate_response(question: str, documents):\n",
    "    formatted_docs = \"\\n\\n\".join(doc.page_content for doc in documents)\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": RAG_SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": f\"Context: {formatted_docs}\\n\\nQuestion: {question}\"}\n",
    "    ]\n",
    "    return call_openai(messages)\n",
    "\n",
    "@traceable(run_type=\"chain\")\n",
    "def langsmith_rag(question: str):\n",
    "    documents = retrieve_documents(question)\n",
    "    response = generate_response(question, documents)\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running over Different pieces of Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Version\n",
    "\n",
    "You can execute an experiment on a specific version of a dataset in the sdk by using the `as_of` parameter in `list_examples`\n",
    "\n",
    "Let's try running on just our initial dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mas_of\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minitial dataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# We use as_of to specify a version\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_concise_enough\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minitial dataset version\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1081\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1065\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1066\u001b[39m experiment_, runs = _resolve_experiment(experiment, runs, client)\n\u001b[32m   1068\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir := ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1083\u001b[39m     cache_path = pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1455\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1457\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(dataset_name=dataset_name, as_of=\"initial dataset\"),   # We use as_of to specify a version\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"initial dataset version\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Dataset Split\n",
    "\n",
    "You can run an experiment on a specific split of your dataset, let's try running on the Crucial Examples split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mStopIteration\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_examples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCrucial Examples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# We pass in a list of Splits\u001b[39;49;00m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_concise_enough\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCrucial Examples split\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      6\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1081\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1065\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1066\u001b[39m experiment_, runs = _resolve_experiment(experiment, runs, client)\n\u001b[32m   1068\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir := ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1083\u001b[39m     cache_path = pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1455\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1457\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[31mStopIteration\u001b[39m: "
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(dataset_name=dataset_name, splits=[\"Crucial Examples\"]),  # We pass in a list of Splits\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"Crucial Examples split\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Specific Data Points\n",
    "\n",
    "You can specify individual data points to run an experiment over as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "LangSmithError",
     "evalue": "Failed to GET /examples in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=1f9560b2-c8e9-4460-8d1e-9a99f230e018', '{\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}')",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\utils.py:154\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    153\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m154\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\requests\\models.py:1026\u001b[39m, in \u001b[36mResponse.raise_for_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1025\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response=\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[31mHTTPError\u001b[39m: 422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=1f9560b2-c8e9-4460-8d1e-9a99f230e018",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mHTTPError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\client.py:875\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    869\u001b[39m     response = \u001b[38;5;28mself\u001b[39m.session.request(\n\u001b[32m    870\u001b[39m         method,\n\u001b[32m    871\u001b[39m         _construct_url(\u001b[38;5;28mself\u001b[39m.api_url, pathname),\n\u001b[32m    872\u001b[39m         stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    873\u001b[39m         **request_kwargs,\n\u001b[32m    874\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m875\u001b[39m \u001b[43mls_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_status_with_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\utils.py:156\u001b[39m, in \u001b[36mraise_for_status_with_text\u001b[39m\u001b[34m(response)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m requests.HTTPError(\u001b[38;5;28mstr\u001b[39m(e), response.text) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mHTTPError\u001b[39m: [Errno 422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=1f9560b2-c8e9-4460-8d1e-9a99f230e018] {\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mLangSmithError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlist_examples\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample_ids\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# We pass in a specific list of example_ids\u001b[39;49;00m\n\u001b[32m      6\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# TODO: You will need to paste in your own example ids for this to work!\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_concise_enough\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtwo specific example ids\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:423\u001b[39m, in \u001b[36mevaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling, **kwargs)\u001b[39m\n\u001b[32m    421\u001b[39m     _warn_once(\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\u001b[33mupload_results\u001b[39m\u001b[33m'\u001b[39m\u001b[33m parameter is in beta.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    422\u001b[39m logger.debug(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRunning evaluation over target system \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m423\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_evaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mOptional\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSequence\u001b[49m\u001b[43m[\u001b[49m\u001b[43mEVALUATOR_T\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m=\u001b[49m\u001b[43msummary_evaluators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    430\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_concurrency\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    437\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    438\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1081\u001b[39m, in \u001b[36m_evaluate\u001b[39m\u001b[34m(target, data, evaluators, summary_evaluators, metadata, experiment_prefix, description, max_concurrency, num_repetitions, client, blocking, experiment, upload_results, error_handling)\u001b[39m\n\u001b[32m   1065\u001b[39m runs = \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m _is_callable(target) \u001b[38;5;28;01melse\u001b[39;00m cast(Iterable[schemas.Run], target)\n\u001b[32m   1066\u001b[39m experiment_, runs = _resolve_experiment(experiment, runs, client)\n\u001b[32m   1068\u001b[39m manager = \u001b[43m_ExperimentManager\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1069\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1070\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1071\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1072\u001b[39m \u001b[43m    \u001b[49m\u001b[43mexperiment\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperiment_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexperiment_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_repetitions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1075\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If provided, we don't need to create a new experiment.\u001b[39;49;00m\n\u001b[32m   1076\u001b[39m \u001b[43m    \u001b[49m\u001b[43mruns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mruns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Create or resolve the experiment.\u001b[39;49;00m\n\u001b[32m   1078\u001b[39m \u001b[43m    \u001b[49m\u001b[43minclude_attachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_include_attachments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevaluators\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1079\u001b[39m \u001b[43m    \u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m=\u001b[49m\u001b[43mupload_results\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1080\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_handling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_dir := ls_utils.get_cache_dir(\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1083\u001b[39m     cache_path = pathlib.Path(cache_dir) / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanager.dataset_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.yaml\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\evaluation\\_runner.py:1455\u001b[39m, in \u001b[36m_ExperimentManager.start\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1454\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstart\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> _ExperimentManager:\n\u001b[32m-> \u001b[39m\u001b[32m1455\u001b[39m     first_example = \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mitertools\u001b[49m\u001b[43m.\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mexamples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1456\u001b[39m     project = \u001b[38;5;28mself\u001b[39m._get_project(first_example) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._upload_results \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1457\u001b[39m     \u001b[38;5;28mself\u001b[39m._print_experiment_start(project, first_example)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\client.py:5186\u001b[39m, in \u001b[36mClient.list_examples\u001b[39m\u001b[34m(self, dataset_id, dataset_name, example_ids, as_of, splits, inline_s3_urls, offset, limit, metadata, filter, include_attachments, **kwargs)\u001b[39m\n\u001b[32m   5184\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m include_attachments:\n\u001b[32m   5185\u001b[39m     params[\u001b[33m\"\u001b[39m\u001b[33mselect\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[33m\"\u001b[39m\u001b[33mattachment_urls\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33moutputs\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmetadata\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m-> \u001b[39m\u001b[32m5186\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m   5187\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_paginated_list\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/examples\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5188\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   5189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m_convert_stored_attachments_to_attachments_dict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5190\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattachments_key\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattachment_urls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_url\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_url\u001b[49m\n\u001b[32m   5191\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5193\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mls_schemas\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5194\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mexample\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[43m!=\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mattachment_urls\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5195\u001b[39m \u001b[43m        \u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m=\u001b[49m\u001b[43mattachments\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5196\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_host_url\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_host_url\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5197\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_tenant_id\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_optional_tenant_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   5198\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\client.py:1031\u001b[39m, in \u001b[36mClient._get_paginated_list\u001b[39m\u001b[34m(self, path, params)\u001b[39m\n\u001b[32m   1029\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m   1030\u001b[39m     params_[\u001b[33m\"\u001b[39m\u001b[33moffset\u001b[39m\u001b[33m\"\u001b[39m] = offset\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1032\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1033\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1034\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1035\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1036\u001b[39m     items = response.json()\n\u001b[32m   1037\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m items:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bhavy\\OneDrive\\Desktop\\College\\3rd sem\\MAT496\\venv\\Lib\\site-packages\\langsmith\\client.py:924\u001b[39m, in \u001b[36mClient.request_with_retries\u001b[39m\u001b[34m(self, method, pathname, request_kwargs, stop_after_attempt, retry_on, to_ignore, handle_response, _context, **kwargs)\u001b[39m\n\u001b[32m    920\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithConflictError(\n\u001b[32m    921\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mConflict for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m_context\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    922\u001b[39m         )\n\u001b[32m    923\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m924\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithError(\n\u001b[32m    925\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    926\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    927\u001b[39m         )\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    930\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ls_utils.LangSmithUserError(\n\u001b[32m    931\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmethod\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpathname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m in LangSmith API. \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mrepr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    932\u001b[39m     )\n",
      "\u001b[31mLangSmithError\u001b[39m: Failed to GET /examples in LangSmith API. HTTPError('422 Client Error: unknown for url: https://api.smith.langchain.com/examples?offset=0&id=&id=&inline_s3_urls=True&limit=100&dataset=1f9560b2-c8e9-4460-8d1e-9a99f230e018', '{\"detail\":[\"query.id.0: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\",\"query.id.1: Input should be a valid UUID, invalid length: expected length 32 for simple format, found 0\"]}')"
     ]
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=client.list_examples(\n",
    "        dataset_name=dataset_name, \n",
    "        example_ids=[   # We pass in a specific list of example_ids\n",
    "            # TODO: You will need to paste in your own example ids for this to work!\n",
    "            \"\",\n",
    "            \"\"\n",
    "        ]\n",
    "    ),\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"two specific example ids\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Repetitions\n",
    "\n",
    "You can run an experiment several times to make sure you have consistent results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'two repetitions-ec5afbb0' at:\n",
      "https://smith.langchain.com/o/6b354ec6-3f46-4558-9cde-6a933975f725/datasets/1f9560b2-c8e9-4460-8d1e-9a99f230e018/compare?selectedSessions=f7ccec71-1267-499f-ace7-9198bfbec017\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:34,  1.73s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.056642</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>59527408-03ed-4554-bdb3-ce0f261cc134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.144726</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>1f36ebd4-ea6d-4547-be14-eed34a083d5d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>To pass metadata with `@traceable`, you can us...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.459387</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>1d7c6096-21df-4c3c-910f-f359ecb2d44d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith when using Lang...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.915445</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>a75d3994-b575-4554-bb3a-9a5723ea2d4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.797915</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>efda32fb-cd7c-4409-b095-a3c83b78bb12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is not designed for finetuning o...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.278775</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>acdf9dd2-04e5-4bf6-a2aa-1ee7970dc1a9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is used to streamline the developmen...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.476902</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>23a60914-8619-443e-ba50-c729d74d3676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>The `@traceable` decorator is used to trace or...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.842155</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>805fba69-8f0e-4fbc-97ae-4d28456338ae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith has testing capabilities that allow ...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.463349</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>92f5767f-1e19-40bb-b5db-1d2c940721b7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.843642</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>a9841019-1629-4fb2-b62a-cff911efba99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826093</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>7b50ffbb-ba44-4bf2-94b0-5aeb12d7fa4d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>0.997699</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>573cd211-8d5f-4fe0-b968-af13cd3d75b8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>I don't know.</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.984916</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>83ed2550-1c13-44ca-a033-32634bf434c7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith in LangChain, y...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.264962</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>3b4942cf-59df-48a6-8e6d-03de64e231b3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>You can create user feedback using the LangSmi...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.899591</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>88de2ca2-93b2-420b-a501-49c13582ea2b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith cannot be used for finetuning an...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.389290</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>b45d79bc-8fff-4456-aa5f-5e0dba32584b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is used for building, evaluating, an...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.309288</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>7454fade-9a36-41aa-b307-909d6c79e2f1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To use the `@traceable` decorator, you would t...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.375591</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>abf486a0-ad55-46b9-92f7-2722c77a8462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith provides capabilities for testing LL...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.909428</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>99069309-7593-49e1-b06a-d3a0d95813a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>No, LangSmith does not support offline evaluat...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.779361</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>1c94224d-e3d8-4316-997d-6b43f0c0fb10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults two repetitions-ec5afbb0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"two repetitions\",\n",
    "    num_repetitions=2   # This field defaults to 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Concurrency\n",
    "You can also kick off concurrent threads of execution to make your experiments finish faster!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'concurrency-5421f623' at:\n",
      "https://smith.langchain.com/o/6b354ec6-3f46-4558-9cde-6a933975f725/datasets/1f9560b2-c8e9-4460-8d1e-9a99f230e018/compare?selectedSessions=73f6ccc3-1fde-4d1e-b4bd-2561ae086502\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.51it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782395</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>6ae351c0-2b76-46f7-963e-343e0a001c24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.458477</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>0f7ebf33-9d65-4192-9cfc-ffa7ed4e05d4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>You can pass metadata in with `@traceable` by ...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.932800</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>539a8199-6711-4af0-b82b-e7ea257d267c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing to LangSmith if you're using...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.889353</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>019e09b3-9459-493d-89f7-3525f270b761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is not intended for finetuning o...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.172049</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>0ef3f178-e20d-46f5-935a-f529cf717095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.508440</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>f87ccb27-dccb-4f87-af0e-828ebd1e8d21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is used for developing, evaluating, ...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.036944</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>ffbe3916-c9e1-4af6-a826-41df2cc28b20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>No, LangSmith does not support offline evaluat...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.778809</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>02ddf033-059c-47da-a996-cb5001f4a971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>To trace with the `@traceable` decorator, you ...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.718285</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>f97a87f9-127c-466e-a7c4-7f0c1f4f92a3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith offers testing capabilities for anal...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.179770</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>2c9fd429-bfb2-41a5-8ab0-f3c042610e60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults concurrency-5421f623>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"concurrency\",\n",
    "    max_concurrency=3,  # This defaults to None, so this is an improvement!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Metadata \n",
    "\n",
    "You can (and should) add metadata to your experiments, to make them easier to find in the UI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "View the evaluation results for experiment: 'metadata added-c17164ca' at:\n",
      "https://smith.langchain.com/o/6b354ec6-3f46-4558-9cde-6a933975f725/datasets/1f9560b2-c8e9-4460-8d1e-9a99f230e018/compare?selectedSessions=011ce4ba-d79e-4862-8827-effdf0a11547\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:17,  1.72s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs.question</th>\n",
       "      <th>outputs.output</th>\n",
       "      <th>error</th>\n",
       "      <th>reference.output</th>\n",
       "      <th>feedback.is_concise</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>example_id</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Does LangSmith support online evaluation?</td>\n",
       "      <td>Yes, LangSmith supports online evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports online evaluation as a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.699183</td>\n",
       "      <td>0306a335-318c-49ae-8fc0-7c18f5fe916d</td>\n",
       "      <td>83924472-be4b-475a-b944-480c8913ef30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Can LangSmith be used to evaluate agents?</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used to evaluate agents....</td>\n",
       "      <td>1</td>\n",
       "      <td>1.293176</td>\n",
       "      <td>2f2966e9-11b2-44c5-9afe-4fad843c0c20</td>\n",
       "      <td>5cb49419-9e2b-4924-8030-3203f91b99cb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How do I pass metadata in with @traceable?</td>\n",
       "      <td>To pass metadata with the `@traceable` annotat...</td>\n",
       "      <td>None</td>\n",
       "      <td>You can pass metadata with the @traceable deco...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.582009</td>\n",
       "      <td>526dcd70-a817-4246-bdc9-9d63ff2e1cda</td>\n",
       "      <td>f23ab45f-5aa5-4bb3-b8ff-b1c1e116e0c8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How do I set up tracing to LangSmith if I'm us...</td>\n",
       "      <td>To set up tracing with LangSmith while using L...</td>\n",
       "      <td>None</td>\n",
       "      <td>To set up tracing to LangSmith while using Lan...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.673400</td>\n",
       "      <td>78efc721-8384-4175-8dbd-da3adf38385f</td>\n",
       "      <td>4cea0bef-8efb-4cb4-894e-b4e47f12b6c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I create user feedback with the LangSmi...</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>None</td>\n",
       "      <td>To create user feedback with the LangSmith SDK...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.950975</td>\n",
       "      <td>7e152e37-d966-45de-9dd6-3ff554fe2693</td>\n",
       "      <td>4e3f418d-7c06-4c12-9b05-68d079d56643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Can LangSmith be used for finetuning and model...</td>\n",
       "      <td>No, LangSmith is not used for finetuning and m...</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith can be used for fine-tuning and...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.243838</td>\n",
       "      <td>8e1fddd0-eabb-42d5-8d17-0ff3dd9aced2</td>\n",
       "      <td>10cd84e0-1d59-4df0-8987-a06f6dbec5fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>What is LangSmith used for in three sentences?</td>\n",
       "      <td>LangSmith is used for developing, testing, deb...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith is a platform designed for the devel...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.919292</td>\n",
       "      <td>a5d2efac-09b1-4faf-bf21-4162aa00c44f</td>\n",
       "      <td>272c4ebc-7f37-4370-b855-1d34c05f5c6f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>How can I trace with the @traceable decorator?</td>\n",
       "      <td>The `@traceable` decorator is used to enable t...</td>\n",
       "      <td>None</td>\n",
       "      <td>To trace with the @traceable decorator in Pyth...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.657677</td>\n",
       "      <td>d5f61dcb-2657-4dac-bad0-475ee89d851d</td>\n",
       "      <td>d45befe4-5cb0-4c19-a371-2ffe80e534f6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>What testing capabilities does LangSmith have?</td>\n",
       "      <td>LangSmith offers testing capabilities that inc...</td>\n",
       "      <td>None</td>\n",
       "      <td>LangSmith offers capabilities for creating dat...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.574833</td>\n",
       "      <td>e982f99f-81af-49e0-8f60-7b7a546d906d</td>\n",
       "      <td>f957484d-a544-4819-a9cf-f93dc5b81be5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Does LangSmith support offline evaluation?</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation.</td>\n",
       "      <td>None</td>\n",
       "      <td>Yes, LangSmith supports offline evaluation thr...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.742602</td>\n",
       "      <td>f57fa9bf-bf79-471a-af5a-a07172ea916d</td>\n",
       "      <td>a327dfd2-bb05-425a-899a-40fdbb6e535f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<ExperimentResults metadata added-c17164ca>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(\n",
    "    target_function,\n",
    "    data=dataset_name,\n",
    "    evaluators=[is_concise_enough],\n",
    "    experiment_prefix=\"metadata added\",\n",
    "    metadata={  # We can pass custom metadata for the experiment, such as the model name\n",
    "        \"model_name\": MODEL_NAME\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
